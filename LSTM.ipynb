{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mindata.txt', 'labels.txt', 'reviews.txt']\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import os\n",
    "from string import punctuation\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "print(os.listdir('data'))\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将数据转为数字的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/labels.txt','r') as f:\n",
    "    labels = f.readlines()\n",
    "labels = \"\".join(labels).split('\\n')\n",
    "labels = torch.Tensor([1 if label=='positive' else 0 for label in labels]).long()\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t',\n",
       " 'story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/reviews.txt') as f:\n",
    "    reviews = \"\".join(f.readlines()).split('\\n')\n",
    "    reviews = [review.strip(\" \") for review in reviews]\n",
    "\n",
    "reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    pattern = r\"[!\\\"#$%&'()*+,-./:;<=>?[\\]@^_`{|}\\\\\\\\~]\"\n",
    "    text = [re.sub(pattern,\"\",doc) for doc in text]\n",
    "    allwords = \" \".join(text).split()\n",
    "    return text,allwords\n",
    "\n",
    "reviews,allwords = preprocessing(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25001 25001\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews),len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter(allwords)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'a', 'of', 'to', 'is', 'br', 'it', 'in', 'i']\n"
     ]
    }
   ],
   "source": [
    "words = [word for word,_ in words.most_common(30000)]\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {word:index+1 for index,word in enumerate(words)}\n",
    "index_to_word = {index+1:word for index,word in enumerate(words)}\n",
    "word_to_index['<UNK>'] = 0\n",
    "index_to_word[0] = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25001\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_index(sentences):\n",
    "    sentence_index = []\n",
    "    for sentence in sentences:\n",
    "        sentence_index.append([word_to_index.get(word,0) for word in sentence.split()])\n",
    "    return sentence_index\n",
    "\n",
    "reviews_index = sentence_to_index(reviews)\n",
    "print(len(reviews_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对齐句子长度 应该在embedding之后再对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.  130.  179.  293. 2514.]\n"
     ]
    }
   ],
   "source": [
    "reviews_len = [len(review) for review in reviews_index]\n",
    "percentiles = np.array([0, 25, 50, 75,100])\n",
    "ptiles_vers = np.percentile(reviews_len, percentiles)\n",
    "print(ptiles_vers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(reviews_len,bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "        21025,   308,     6,     3,  1050,   207,     8,  2138,    32,     1,\n",
      "          171,    57,    15,    49,    81,  5785,    44,   382,   110,   140,\n",
      "           15,  5194,    60,   154,     9,     1,  4975,  5852,   475,    71,\n",
      "            5,   260,    12, 21025,   308,    13,  1978,     6,    74,  2395,\n",
      "            5,   613,    73,     6,  5194,     1, 24103,     5,  1983, 10166,\n",
      "            1,  5786,  1499,    36,    51,    66,   204,   145,    67,  1199,\n",
      "         5194, 19869,     1,     0,     4,     1,   221,   883,    31,  2988,\n",
      "           71,     4,     1,  5787,    10,   686,     2,    67,  1499,    54,\n",
      "           10,   216,     1,   383,     9,    62,     3,  1406,  3686,   783,\n",
      "            5,  3483,   180,     1,   382,    10,  1212, 13583,    32,   308,\n",
      "            3,   349,   341,  2913,    10,   143,   127,     5,  7690,    30,\n",
      "            4,   129,  5194,  1406,  2326,     5, 21025,   308,    10,   528,\n",
      "           12,   109,  1448,     4,    60,   543,   102,    12, 21025,   308,\n",
      "            6,   227,  4146,    48,     3,  2211,    12,     8,   215,    23])\n"
     ]
    }
   ],
   "source": [
    "def pad_text(encoded_reviews, seq_length):\n",
    "    \n",
    "    reviews = []\n",
    "    \n",
    "    for review in encoded_reviews:\n",
    "        if len(review) >= seq_length:\n",
    "            reviews.append(review[:seq_length])\n",
    "        else:\n",
    "            reviews.append([0]*(seq_length-len(review))+review)\n",
    "        \n",
    "    return torch.Tensor(reviews).long()\n",
    "seq_length = 300\n",
    "padded_reviews = pad_text(reviews_index,seq_length)\n",
    "print(len(padded_reviews[1]))\n",
    "print(padded_reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "valid_ratio = 0.1\n",
    "total = padded_reviews.shape[0]\n",
    "train_cutoff = int(total * train_ratio)\n",
    "valid_cutoff = int(total * (train_ratio+valid_ratio))\n",
    "\n",
    "train_x, train_y = padded_reviews[:train_cutoff], labels[:train_cutoff]\n",
    "valid_x, valid_y = padded_reviews[train_cutoff:valid_cutoff], labels[train_cutoff:valid_cutoff]\n",
    "test_x, test_y = padded_reviews[valid_cutoff:], labels[valid_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17500, 300])\n",
      "torch.Size([2500, 300])\n",
      "torch.Size([5001, 300])\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(valid_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_x, train_y)\n",
    "valid_data = TensorDataset(valid_x, valid_y)\n",
    "test_data = TensorDataset(test_x, test_y)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 300]) torch.Size([64])\n",
      "torch.Size([64, 300]) torch.Size([64])\n",
      "torch.Size([64, 300]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for index,(train_x,train_y) in enumerate(train_loader):\n",
    "    if index>2:\n",
    "        break\n",
    "    print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab_size,emb_size,hidden_size,n_layers,out_size):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb = nn.Embedding(vocab_size,emb_size,padding_idx=0)\n",
    "        self.rnn = nn.RNN(emb_size,hidden_size,num_layers=n_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,out_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        emb = self.emb(x) #batch_size*sequence_size*embed_size\n",
    "        rnn_out,h = self.rnn(emb) #batch_size*sequence_size*hidden_size\n",
    "        h = h.squeeze()\n",
    "        output = torch.sigmoid(self.fc(h))\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_SIZE = 300001\n",
    "EMB_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "N_LAYERS = 1\n",
    "DROP_P = 0.5\n",
    "OUTPUT_SIZE = 1\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 100\n",
    "CLIP = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RNN(VOC_SIZE,EMB_SIZE,HIDDEN_SIZE,N_LAYERS,OUTPUT_SIZE)\n",
    "model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (emb): Embedding(300001, 128, padding_idx=0)\n",
       "  (rnn): RNN(128, 256, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100, step 0, Train Loss:0.7186, Val Loss:0.8619\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1f45b201b92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/opt/miniconda3/envs/dp/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    #if epoch==2:\n",
    "    #   break\n",
    "    for index,(train_x,train_y) in enumerate(train_loader):\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        output = model(train_x)\n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            loss = criterion(output.squeeze(),train_y.float())\n",
    "        except:\n",
    "            print(output.shape)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        if index%10==0:\n",
    "            model.eval()\n",
    "            v_losses = []\n",
    "            for val_x,val_y in valid_loader:\n",
    "                val_x = val_x.to(device)\n",
    "                val_y = val_y.to(device)\n",
    "                output = model(val_x)\n",
    "                v_loss = criterion(output.squeeze(),val_y.float()) \n",
    "                v_losses.append(v_loss.item())\n",
    "                \n",
    "            print(\"epoch {}/{}, step {}, Train Loss:{:.4f}, Val Loss:{:.4f}\"\\\n",
    "                  .format(epoch+1,EPOCHS,index,loss.item(),np.mean(v_losses)))\n",
    "            model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
