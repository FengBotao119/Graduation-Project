---
typora-root-url: img
---

# Graduation-Project

This project is based on the audio/vedio emotion competition.

## Models

### TEXT

|       Model       | Accuracy | Precision | Recall | F1 Score |
| :---------------: | :------: | :-------: | :----: | :------: |
| Embedding Average |          |           |        |          |
|      biLSTM       |          |           |        |          |
| biLSTM+attention  |          |           |        |          |
|        HAN        |          |           |        |          |

### VIDEO

- I'm going to use [OpenFace](https://github.com/TadasBaltrusaitis/OpenFace) to extract face landmarks to train a model which can capture people's expression
- [Expression in-the-Wild (ExpW) Dataset](http://mmlab.ie.cuhk.edu.hk/projects/socialrelation/index.html)

![](/pic1.jpg)

### AUDIO

- 

## Reference

* Yang, Zichao, et al. "Hierarchical attention networks for document classification." *Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies*. 2016.

* **OpenFace 2.0: Facial Behavior Analysis Toolkit** Tadas Baltru≈°aitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency, *IEEE International Conference on Automatic Face and Gesture Recognition*, 2018

* Munasinghe M. Facial expression recognition using facial landmarks and random forest classifier[C]//2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). IEEE, 2018: 423-427.

  



